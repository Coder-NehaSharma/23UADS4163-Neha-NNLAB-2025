{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "The objective of this project is to develop a deep learning model capable of classifying medical images into different categories using a transfer learning approach with a pretrained MobileNetV2 model.\n",
    "Description of Model:\n",
    "\n",
    "This project utilizes the MobileNetV2 architecture, a lightweight convolutional neural network pre-trained on the ImageNet dataset. The final fully connected (FC) layer is replaced to match the number of classes present in the Medical MNIST dataset. By using transfer learning, the model leverages learned features from a general image classification task (ImageNet) and fine-tunes them for the medical image classification task. This allows the model to efficiently classify medical images with a relatively smaller dataset.\n",
    "Description of Code:\n",
    "\n",
    "Libraries Used:\n",
    "TensorFlow\n",
    "MedMNIST\n",
    "Numpy\n",
    "Matplotlib\n",
    "Dataset Handling:\n",
    "Dataset: Medical MNIST dataset (specifically PathMNIST in this case) is loaded using the medmnist library.\n",
    "Preprocessing: Images are resized to 224x224 (to match MobileNetV2 input size), normalized, and converted to tensors.\n",
    "Splits: The dataset is split into training, validation, and test sets, and DataLoader is used to create batches.\n",
    "Model Definition:\n",
    "A pretrained MobileNetV2 model is loaded from TensorFlow Keras Applications.\n",
    "The fully connected (FC) layer of MobileNetV2 is replaced with a new FC layer to output predictions based on the number of classes in the dataset (10 classes for PathMNIST).\n",
    "The base layers of MobileNetV2 are frozen to prevent weight updates during training, and only the new layers are trained.\n",
    "Training Loop:\n",
    "The model is trained for 10 epochs using the Adam optimizer.\n",
    "Training and validation accuracy and loss are tracked during the process.\n",
    "The best-performing model on the validation set is saved for further evaluation.\n",
    "Visualization:\n",
    "A loss curve is plotted to visualize the training and validation loss during the training process.\n",
    "Training and validation accuracy are printed at each epoch.\n",
    "Performance Evaluation:\n",
    "\n",
    "Training & Validation Metrics:\n",
    "Accuracy and loss are printed for both training and validation sets across epochs.\n",
    "Best Model: The model with the highest validation accuracy is saved and considered the best-performing model.\n",
    "Visualization:\n",
    "Loss curve: A plot is generated to track the loss over epochs and visualize how the training progresses.\n",
    "Expected Performance Metrics:\n",
    "Accuracy: The model is expected to achieve good accuracy on the validation set after fine-tuning.\n",
    "Loss: The training loss should decrease over epochs as the model fine-tunes itself for the task.\n",
    "Performance Variation: Actual accuracy and loss may vary depending on the dataset quality, the number of samples, and the complexity of the task.\n",
    "My Comments:\n",
    "\n",
    "The modular structure of the model and training pipeline allows easy modification to experiment with different architectures, optimizers, or datasets. The transfer learning approach helps improve model performance even with a relatively smaller medical image dataset, leveraging the power of pretrained features.\n",
    "For further improvements, you might consider:\n",
    "Data Augmentation: Adding techniques like rotation, zoom, and flipping to improve the model's generalization.\n",
    "Experimenting with other Pretrained Models: Trying deeper models such as ResNet50 or InceptionV3 for potentially better results.\n",
    "Hyperparameter Tuning: Experimenting with learning rates, dropout rates, and batch sizes to optimize the model.\n",
    "Ensemble Models: Combining the predictions of several models to improve overall performance.\n",
    "Model Limitations:\n",
    "\n",
    "Dataset Variability: The model might struggle if the dataset has high variability in terms of image quality or class imbalance.\n",
    "Limited Dataset Size: If the dataset is too small, the model might overfit. In such cases, more data or augmentation techniques should be considered.\n",
    "Frozen Layers: Only the final layers of MobileNetV2 are trained. More advanced techniques, such as fine-tuning more layers of the base model, can be explored for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medmnist\n",
      "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (1.4.1.post1)\n",
      "Requirement already satisfied: scikit-image in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (0.22.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (4.65.0)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (10.2.0)\n",
      "Requirement already satisfied: fire in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (0.6.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (from medmnist) (0.17.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->medmnist) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->medmnist) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->medmnist) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->medmnist) (1.11.4)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->medmnist) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->medmnist) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->medmnist) (2023.4.12)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->medmnist) (0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->medmnist) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->medmnist) (2.2.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch->medmnist) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch->medmnist) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch->medmnist) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch->medmnist) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch->medmnist) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: medmnist\n",
      "Successfully installed medmnist-3.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install medmnist tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/nehasharma/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /Users/nehasharma/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /Users/nehasharma/.medmnist/pathmnist.npz\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Specify the dataset\n",
    "data_flag = 'pathmnist'\n",
    "download = True\n",
    "\n",
    "# Get dataset info\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "# Define transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = DataClass(split='train', transform=data_transforms, download=download)\n",
    "val_dataset = DataClass(split='val', transform=data_transforms, download=download)\n",
    "test_dataset = DataClass(split='test', transform=data_transforms, download=download)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python_class': 'PathMNIST', 'description': 'The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.', 'url': 'https://zenodo.org/records/10519652/files/pathmnist.npz?download=1', 'MD5': 'a8b06965200029087d5bd730944a56c1', 'url_64': 'https://zenodo.org/records/10519652/files/pathmnist_64.npz?download=1', 'MD5_64': '55aa9c1e0525abe5a6b9d8343a507616', 'url_128': 'https://zenodo.org/records/10519652/files/pathmnist_128.npz?download=1', 'MD5_128': 'ac42d08fb904d92c244187169d1fd1d9', 'url_224': 'https://zenodo.org/records/10519652/files/pathmnist_224.npz?download=1', 'MD5_224': '2c51a510bcdc9cf8ddb2af93af1eadec', 'task': 'multi-class', 'label': {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}, 'n_channels': 3, 'n_samples': {'train': 89996, 'val': 10004, 'test': 7180}, 'license': 'CC BY 4.0'}\n"
     ]
    }
   ],
   "source": [
    "# Print the info dictionary to check its structure\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "url = 'https://zenodo.org/records/10519652/files/pathmnist_224.npz?download=1'\n",
    "file_name = 'pathmnist_224.npz'\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open(file_name, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "dataset = np.load(file_name)\n",
    "\n",
    "# Extract images and labels\n",
    "train_images = dataset['train_images']\n",
    "train_labels = dataset['train_labels']\n",
    "val_images = dataset['val_images']\n",
    "val_labels = dataset['val_labels']\n",
    "test_images = dataset['test_images']\n",
    "test_labels = dataset['test_labels']\n",
    "\n",
    "# Normalize images to the range [0, 1]\n",
    "train_images = train_images.astype(np.float32) / 255.0\n",
    "val_images = val_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.astype(np.float32) / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, 9)\n",
    "val_labels = tf.keras.utils.to_categorical(val_labels, 9)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, 9)\n",
    "\n",
    "# Load the pre-trained base model (ResNet50)\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(9, activation='softmax')  # Output layer with 9 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
